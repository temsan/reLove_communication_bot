"""
–¢–µ—Å—Ç–æ–≤—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ LLM.
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ç–µ–∫—É—â—É—é –º–æ–¥–µ–ª—å –∏ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –ø–µ—Ä–µ–∫–ª—é—á–∞–µ—Ç—Å—è –Ω–∞ Grok.
"""
import asyncio
import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))

from relove_bot.config import settings
from relove_bot.rag.llm import LLM
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


async def test_current_model():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç —Ç–µ–∫—É—â—É—é –º–æ–¥–µ–ª—å"""
    print("="*60)
    print("LLM Connection Test")
    print("="*60)
    print(f"\nüìã Current settings:")
    print(f"   Model: {settings.model_name}")
    print(f"   API Base: {settings.llm_api_base}")
    print(f"   API Key: {settings.llm_api_key.get_secret_value()[:10]}...")
    
    print(f"\nüîÑ Testing connection...")
    
    try:
        llm = LLM()
        
        # –ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç
        test_prompt = "–ü—Ä–∏–≤–µ—Ç! –û—Ç–≤–µ—Ç—å –æ–¥–Ω–∏–º —Å–ª–æ–≤–æ–º: —Ä–∞–±–æ—Ç–∞–µ—à—å?"
        
        print(f"\nüì§ Sending test prompt: '{test_prompt}'")
        
        response = await llm.generate_rag_answer(
            context="",
            question=test_prompt
        )
        
        print(f"\n‚úÖ SUCCESS!")
        print(f"üì• Response: {response}")
        print(f"\n‚úÖ Model {settings.model_name} is working!")
        
        return True
        
    except Exception as e:
        print(f"\n‚ùå ERROR!")
        print(f"   Error: {e}")
        print(f"\n‚ùå Model {settings.model_name} is NOT working!")
        
        return False


async def test_grok_model():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç Grok –º–æ–¥–µ–ª—å"""
    print("\n" + "="*60)
    print("Testing Grok Model")
    print("="*60)
    
    # –í—Ä–µ–º–µ–Ω–Ω–æ –º–µ–Ω—è–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
    original_model = settings.model_name
    settings.model_name = "x-ai/grok-beta"
    
    print(f"\nüìã Grok settings:")
    print(f"   Model: {settings.model_name}")
    print(f"   API Base: {settings.llm_api_base}")
    
    try:
        llm = LLM()
        
        test_prompt = "–ü—Ä–∏–≤–µ—Ç! –û—Ç–≤–µ—Ç—å –æ–¥–Ω–∏–º —Å–ª–æ–≤–æ–º: —Ä–∞–±–æ—Ç–∞–µ—à—å?"
        
        print(f"\nüì§ Sending test prompt: '{test_prompt}'")
        
        response = await llm.generate_rag_answer(
            context="",
            question=test_prompt
        )
        
        print(f"\n‚úÖ SUCCESS!")
        print(f"üì• Response: {response}")
        print(f"\n‚úÖ Grok model is working!")
        
        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        settings.model_name = original_model
        
        return True
        
    except Exception as e:
        print(f"\n‚ùå ERROR!")
        print(f"   Error: {e}")
        print(f"\n‚ùå Grok model is NOT working!")
        
        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        settings.model_name = original_model
        
        return False


async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ç–µ–∫—É—â—É—é –º–æ–¥–µ–ª—å
    current_works = await test_current_model()
    
    if current_works:
        print("\n" + "="*60)
        print("‚úÖ Current model is working fine!")
        print("="*60)
        return
    
    # –ï—Å–ª–∏ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç, —Ç–µ—Å—Ç–∏—Ä—É–µ–º Grok
    print("\n‚ö†Ô∏è Current model failed. Testing Grok...")
    
    grok_works = await test_grok_model()
    
    if grok_works:
        print("\n" + "="*60)
        print("üí° RECOMMENDATION")
        print("="*60)
        print("\nUpdate your .env file:")
        print("\n# Change this line:")
        print(f"MODEL_NAME={settings.model_name}")
        print("\n# To this:")
        print("MODEL_NAME=x-ai/grok-beta")
        print("\nOr use the free version:")
        print("MODEL_NAME=x-ai/grok-4.1-fast:free")
        print("="*60)
    else:
        print("\n" + "="*60)
        print("‚ùå Both models failed!")
        print("="*60)
        print("\nPossible issues:")
        print("1. Check your API key")
        print("2. Check internet connection")
        print("3. Check API base URL")
        print("4. Try different model")


if __name__ == "__main__":
    asyncio.run(main())
