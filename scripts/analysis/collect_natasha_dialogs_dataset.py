#!/usr/bin/env python3
"""
–°–±–æ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–∏–∞–ª–æ–≥–æ–≤ –ù–∞—Ç–∞—à–∏ —Å —é–∑–µ—Ä–∞–º–∏ –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏.

–ó–∞–¥–∞—á–∏:
1. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤—Å–µ—Ö –¥–∏–∞–ª–æ–≥–æ–≤ –ù–∞—Ç–∞—à–∏ —Å —é–∑–µ—Ä–∞–º–∏ –∏–∑ –≤—Å–µ—Ö –∫–∞–Ω–∞–ª–æ–≤ reLove
2. –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ —Ñ–æ—Ä–º–∞—Ç –¥–ª—è fine-tuning (question-answer pairs)
3. –°–æ–∑–¥–∞–Ω–∏–µ JSONL –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è OpenAI API
4. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏ –∞–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö
"""
import asyncio
import json
import sys
from pathlib import Path
from typing import List, Dict, Any, Tuple
from datetime import datetime
from collections import defaultdict

sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from telethon import TelegramClient
from relove_bot.config import settings
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/collect_natasha_dialogs.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

# ID –ù–∞—Ç–∞—à–∏ –í–æ–ª–∫–æ—à
NATASHA_ID = 496684653

# –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è –≤ –¥–∞—Ç–∞—Å–µ—Ç
MIN_MESSAGE_LENGTH = 20

# –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –¥–∏–∞–ª–æ–≥–µ
MIN_DIALOG_LENGTH = 2


class NatashaDialogsCollector:
    """–°–±–æ—Ä—â–∏–∫ –¥–∏–∞–ª–æ–≥–æ–≤ –ù–∞—Ç–∞—à–∏ –¥–ª—è –¥–∞—Ç–∞—Å–µ—Ç–∞."""
    
    def __init__(self):
        self.client = TelegramClient(
            settings.tg_session,
            settings.tg_api_id,
            settings.tg_api_hash.get_secret_value()
        )
        
        # –î–∞–Ω–Ω—ã–µ –¥–ª—è –¥–∞—Ç–∞—Å–µ—Ç–∞
        self.dialogs = []  # –í—Å–µ –¥–∏–∞–ª–æ–≥–∏
        self.qa_pairs = []  # Question-answer –ø–∞—Ä—ã
        self.statistics = {
            'total_channels': 0,
            'total_messages': 0,
            'natasha_messages': 0,
            'user_messages': 0,
            'valid_dialogs': 0,
            'channels_processed': []
        }
    
    async def collect_from_all_channels(self, limit_per_channel: int = 2000):
        """–°–æ–±–∏—Ä–∞–µ—Ç –¥–∏–∞–ª–æ–≥–∏ –∏–∑ –≤—Å–µ—Ö –∫–∞–Ω–∞–ª–æ–≤ reLove."""
        logger.info("Starting collection from all reLove channels...")
        
        async for dialog in self.client.iter_dialogs():
            name_lower = dialog.name.lower()
            
            # –¢–æ–ª—å–∫–æ –∫–∞–Ω–∞–ª—ã reLove
            if 'relove' not in name_lower and '—Ä–µ–ª–æ–≤' not in name_lower:
                continue
            
            channel_name = dialog.name
            logger.info(f"\n{'='*70}")
            logger.info(f"Processing: {channel_name}")
            logger.info(f"{'='*70}")
            
            try:
                await self._process_channel(
                    dialog.entity,
                    channel_name,
                    limit_per_channel
                )
                
                self.statistics['channels_processed'].append(channel_name)
                self.statistics['total_channels'] += 1
                
            except Exception as e:
                logger.error(f"‚ùå Error processing {channel_name}: {e}")
    
    async def _process_channel(
        self,
        channel_entity,
        channel_name: str,
        limit: int
    ):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–∏–Ω –∫–∞–Ω–∞–ª."""
        messages_list = []
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è
        async for message in self.client.iter_messages(channel_entity, limit=limit):
            if message.text:
                messages_list.append(message)
        
        logger.info(f"Got {len(messages_list)} messages")
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        messages_list.sort(key=lambda m: m.date)
        
        # –ò—â–µ–º –¥–∏–∞–ª–æ–≥–∏ –ù–∞—Ç–∞—à–∏
        channel_dialogs = 0
        channel_qa_pairs = 0
        
        for i, message in enumerate(messages_list):
            # –ò—â–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –ù–∞—Ç–∞—à–∏
            if message.sender_id == NATASHA_ID and len(message.text) >= MIN_MESSAGE_LENGTH:
                
                # –í–∞—Ä–∏–∞–Ω—Ç 1: –î–∏–∞–ª–æ–≥ —á–µ—Ä–µ–∑ reply_to
                if message.reply_to and message.reply_to.reply_to_msg_id:
                    dialog_data = self._extract_reply_chain_dialog(
                        message,
                        messages_list,
                        channel_name
                    )
                    
                    if dialog_data:
                        self.dialogs.append(dialog_data)
                        
                        # –°–æ–∑–¥–∞—ë–º QA –ø–∞—Ä—ã
                        qa_pair = self._create_qa_pair_from_dialog(dialog_data)
                        if qa_pair:
                            self.qa_pairs.append(qa_pair)
                            channel_qa_pairs += 1
                        
                        channel_dialogs += 1
                
                # –í–∞—Ä–∏–∞–Ω—Ç 2: –î–∏–∞–ª–æ–≥ –ø–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É (–µ—Å–ª–∏ –Ω–µ—Ç reply)
                else:
                    dialog_data = self._extract_context_dialog(
                        message,
                        messages_list,
                        i,
                        channel_name
                    )
                    
                    if dialog_data:
                        self.dialogs.append(dialog_data)
                        
                        # –°–æ–∑–¥–∞—ë–º QA –ø–∞—Ä—ã
                        qa_pair = self._create_qa_pair_from_dialog(dialog_data)
                        if qa_pair:
                            self.qa_pairs.append(qa_pair)
                            channel_qa_pairs += 1
                        
                        channel_dialogs += 1
        
        logger.info(f"‚úÖ Found {channel_dialogs} dialogs, {channel_qa_pairs} QA pairs")
        
        self.statistics['total_messages'] += len(messages_list)
        self.statistics['natasha_messages'] += sum(
            1 for m in messages_list if m.sender_id == NATASHA_ID
        )
        self.statistics['user_messages'] += sum(
            1 for m in messages_list if m.sender_id != NATASHA_ID
        )
        self.statistics['valid_dialogs'] += channel_dialogs
    
    def _extract_reply_chain_dialog(
        self,
        natasha_message,
        messages_list: List,
        channel_name: str
    ) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∏–∞–ª–æ–≥ —á–µ—Ä–µ–∑ —Ü–µ–ø–æ—á–∫—É reply."""
        try:
            # –ò—â–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ, –Ω–∞ –∫–æ—Ç–æ—Ä–æ–µ –æ—Ç–≤–µ—á–∞–µ—Ç –ù–∞—Ç–∞—à–∞
            replied_msg = None
            for msg in messages_list:
                if msg.id == natasha_message.reply_to.reply_to_msg_id:
                    replied_msg = msg
                    break
            
            if not replied_msg or len(replied_msg.text) < MIN_MESSAGE_LENGTH:
                return None
            
            # –°—Ç—Ä–æ–∏–º —Ü–µ–ø–æ—á–∫—É —Ä–µ–ø–ª–∞–µ–≤
            reply_chain = []
            current_msg = replied_msg
            chain_depth = 0
            max_chain_depth = 5
            
            while current_msg and chain_depth < max_chain_depth:
                sender_name = "Unknown"
                if current_msg.sender:
                    sender_name = getattr(current_msg.sender, 'first_name', 'Unknown')
                
                reply_chain.insert(0, {
                    'sender_id': current_msg.sender_id,
                    'sender_name': sender_name,
                    'is_natasha': current_msg.sender_id == NATASHA_ID,
                    'text': current_msg.text,
                    'date': current_msg.date.isoformat(),
                    'message_id': current_msg.id
                })
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É —ç—Ç–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è reply
                if current_msg.reply_to and current_msg.reply_to.reply_to_msg_id:
                    next_msg = None
                    for msg in messages_list:
                        if msg.id == current_msg.reply_to.reply_to_msg_id:
                            next_msg = msg
                            break
                    current_msg = next_msg
                    chain_depth += 1
                else:
                    break
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ù–∞—Ç–∞—à–∏ –≤ –∫–æ–Ω–µ—Ü
            reply_chain.append({
                'sender_id': NATASHA_ID,
                'sender_name': '–ù–∞—Ç–∞—à–∞ –í–æ–ª–∫–æ—à',
                'is_natasha': True,
                'text': natasha_message.text,
                'date': natasha_message.date.isoformat(),
                'message_id': natasha_message.id
            })
            
            if len(reply_chain) < MIN_DIALOG_LENGTH:
                return None
            
            return {
                'channel': channel_name,
                'date': natasha_message.date.isoformat(),
                'type': 'reply_chain',
                'context': reply_chain,
                'user_message': replied_msg.text,
                'natasha_response': natasha_message.text,
                'user_name': getattr(replied_msg.sender, 'first_name', 'Unknown') if replied_msg.sender else 'Unknown'
            }
        
        except Exception as e:
            logger.debug(f"Error extracting reply chain: {e}")
            return None
    
    def _extract_context_dialog(
        self,
        natasha_message,
        messages_list: List,
        message_index: int,
        channel_name: str
    ) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∏–∞–ª–æ–≥ –ø–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É."""
        try:
            # –ë–µ—Ä—ë–º –∫–æ–Ω—Ç–µ–∫—Å—Ç: 2 —Å–æ–æ–±—â–µ–Ω–∏—è –¥–æ, —Å–∞–º–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –ù–∞—Ç–∞—à–∏, 1 –ø–æ—Å–ª–µ
            context_start = max(0, message_index - 2)
            context_end = min(len(messages_list), message_index + 2)
            
            context = []
            user_message = None
            
            for j in range(context_start, context_end):
                msg = messages_list[j]
                
                if len(msg.text) < MIN_MESSAGE_LENGTH:
                    continue
                
                sender_name = "Unknown"
                if msg.sender:
                    sender_name = getattr(msg.sender, 'first_name', 'Unknown')
                
                context.append({
                    'sender_id': msg.sender_id,
                    'sender_name': sender_name,
                    'is_natasha': msg.sender_id == NATASHA_ID,
                    'text': msg.text,
                    'date': msg.date.isoformat(),
                    'message_id': msg.id
                })
                
                # –ó–∞–ø–æ–º–∏–Ω–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –ø–µ—Ä–µ–¥ –ù–∞—Ç–∞—à–µ–π
                if msg.sender_id != NATASHA_ID and j < message_index:
                    user_message = msg.text
            
            if len(context) < MIN_DIALOG_LENGTH or not user_message:
                return None
            
            return {
                'channel': channel_name,
                'date': natasha_message.date.isoformat(),
                'type': 'context',
                'context': context,
                'user_message': user_message,
                'natasha_response': natasha_message.text,
                'user_name': 'Unknown'
            }
        
        except Exception as e:
            logger.debug(f"Error extracting context dialog: {e}")
            return None
    
    def _create_qa_pair_from_dialog(self, dialog: Dict[str, Any]) -> Dict[str, str]:
        """–°–æ–∑–¥–∞—ë—Ç QA –ø–∞—Ä—É –∏–∑ –¥–∏–∞–ª–æ–≥–∞."""
        try:
            # –°–æ–±–∏—Ä–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç (–≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∫—Ä–æ–º–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –æ—Ç–≤–µ—Ç–∞ –ù–∞—Ç–∞—à–∏)
            context_messages = []
            
            for msg in dialog['context'][:-1]:  # –í—Å–µ –∫—Ä–æ–º–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ
                if not msg['is_natasha']:
                    context_messages.append(msg['text'])
            
            if not context_messages:
                return None
            
            # –í–æ–ø—Ä–æ—Å - –ø–æ—Å–ª–µ–¥–Ω–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            question = context_messages[-1] if context_messages else dialog['user_message']
            
            # –û—Ç–≤–µ—Ç - —Å–æ–æ–±—â–µ–Ω–∏–µ –ù–∞—Ç–∞—à–∏
            answer = dialog['natasha_response']
            
            if not question or not answer or len(question) < 10 or len(answer) < 10:
                return None
            
            return {
                'prompt': question,
                'completion': answer,
                'channel': dialog['channel'],
                'date': dialog['date'],
                'user_name': dialog.get('user_name', 'Unknown')
            }
        
        except Exception as e:
            logger.debug(f"Error creating QA pair: {e}")
            return None
    
    async def save_datasets(self) -> Tuple[str, str, str]:
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç—ã –≤ —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö."""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # 1. JSON –¥–∞—Ç–∞—Å–µ—Ç (–ø–æ–ª–Ω—ã–µ –¥–∏–∞–ª–æ–≥–∏)
        json_file = f"data/natasha_dialogs_dataset_{timestamp}.json"
        Path("data").mkdir(exist_ok=True)
        
        dataset_json = {
            'timestamp': timestamp,
            'natasha_id': NATASHA_ID,
            'total_dialogs': len(self.dialogs),
            'total_qa_pairs': len(self.qa_pairs),
            'statistics': self.statistics,
            'dialogs': self.dialogs
        }
        
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(dataset_json, f, ensure_ascii=False, indent=2)
        
        logger.info(f"‚úÖ Saved JSON dataset to: {json_file}")
        
        # 2. JSONL –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è fine-tuning (OpenAI format)
        jsonl_file = f"data/natasha_finetuning_{timestamp}.jsonl"
        
        with open(jsonl_file, 'w', encoding='utf-8') as f:
            for qa_pair in self.qa_pairs:
                # –§–æ—Ä–º–∞—Ç –¥–ª—è OpenAI fine-tuning
                training_example = {
                    "messages": [
                        {
                            "role": "user",
                            "content": qa_pair['prompt']
                        },
                        {
                            "role": "assistant",
                            "content": qa_pair['completion']
                        }
                    ]
                }
                f.write(json.dumps(training_example, ensure_ascii=False) + '\n')
        
        logger.info(f"‚úÖ Saved JSONL dataset to: {jsonl_file}")
        
        # 3. CSV –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        csv_file = f"data/natasha_dialogs_{timestamp}.csv"
        
        import csv
        with open(csv_file, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.DictWriter(
                f,
                fieldnames=['date', 'channel', 'user_name', 'user_message', 'natasha_response', 'message_length']
            )
            writer.writeheader()
            
            for dialog in self.dialogs:
                writer.writerow({
                    'date': dialog['date'],
                    'channel': dialog['channel'],
                    'user_name': dialog.get('user_name', 'Unknown'),
                    'user_message': dialog['user_message'][:100] + '...' if len(dialog['user_message']) > 100 else dialog['user_message'],
                    'natasha_response': dialog['natasha_response'][:100] + '...' if len(dialog['natasha_response']) > 100 else dialog['natasha_response'],
                    'message_length': len(dialog['natasha_response'])
                })
        
        logger.info(f"‚úÖ Saved CSV dataset to: {csv_file}")
        
        return json_file, jsonl_file, csv_file
    
    def print_statistics(self):
        """–í—ã–≤–æ–¥–∏—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É."""
        logger.info(f"\n{'='*70}")
        logger.info("DATASET STATISTICS")
        logger.info(f"{'='*70}")
        logger.info(f"Total channels processed: {self.statistics['total_channels']}")
        logger.info(f"Total messages: {self.statistics['total_messages']}")
        logger.info(f"Natasha's messages: {self.statistics['natasha_messages']}")
        logger.info(f"User messages: {self.statistics['user_messages']}")
        logger.info(f"Valid dialogs: {self.statistics['valid_dialogs']}")
        logger.info(f"QA pairs for fine-tuning: {len(self.qa_pairs)}")
        logger.info(f"\nChannels processed:")
        for channel in self.statistics['channels_processed']:
            logger.info(f"  - {channel}")
        logger.info(f"{'='*70}\n")
    
    def print_sample_dialogs(self, count: int = 3):
        """–í—ã–≤–æ–¥–∏—Ç –ø—Ä–∏–º–µ—Ä—ã –¥–∏–∞–ª–æ–≥–æ–≤."""
        logger.info(f"\n{'='*70}")
        logger.info("SAMPLE DIALOGS")
        logger.info(f"{'='*70}\n")
        
        for i, dialog in enumerate(self.dialogs[:count]):
            logger.info(f"Dialog #{i+1} - {dialog['channel']} ({dialog['date']})")
            logger.info("-" * 70)
            
            for msg in dialog['context']:
                role = "üî• –ù–ê–¢–ê–®–ê" if msg['is_natasha'] else f"üë§ {msg['sender_name']}"
                text = msg['text'][:200] + "..." if len(msg['text']) > 200 else msg['text']
                logger.info(f"{role}: {text}")
            
            logger.info("")


async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    import argparse
    
    parser = argparse.ArgumentParser(
        description="Collect Natasha's dialogs for model fine-tuning"
    )
    parser.add_argument(
        '--limit',
        type=int,
        default=2000,
        help='Limit messages per channel (default: 2000)'
    )
    parser.add_argument(
        '--sample',
        type=int,
        default=3,
        help='Show N sample dialogs (default: 3)'
    )
    
    args = parser.parse_args()
    
    print("\n" + "="*70)
    print("NATASHA DIALOGS DATASET COLLECTION")
    print("="*70 + "\n")
    
    collector = NatashaDialogsCollector()
    
    try:
        await collector.client.connect()
        
        if not await collector.client.is_user_authorized():
            logger.error("‚ùå Not authorized!")
            return
        
        logger.info("‚úÖ Connected to Telegram\n")
        
        # –°–æ–±–∏—Ä–∞–µ–º –¥–∏–∞–ª–æ–≥–∏
        await collector.collect_from_all_channels(limit_per_channel=args.limit)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞—Ç–∞—Å–µ—Ç—ã
        json_file, jsonl_file, csv_file = await collector.save_datasets()
        
        # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        collector.print_statistics()
        
        # –í—ã–≤–æ–¥–∏–º –ø—Ä–∏–º–µ—Ä—ã
        collector.print_sample_dialogs(count=args.sample)
        
        logger.info(f"\n{'='*70}")
        logger.info("FILES CREATED")
        logger.info(f"{'='*70}")
        logger.info(f"1. JSON (full dialogs): {json_file}")
        logger.info(f"2. JSONL (fine-tuning): {jsonl_file}")
        logger.info(f"3. CSV (analysis): {csv_file}")
        logger.info(f"{'='*70}\n")
        
    except Exception as e:
        logger.error(f"‚ùå Fatal error: {e}", exc_info=True)
    
    finally:
        await collector.client.disconnect()
        logger.info("üëã Disconnected")


if __name__ == "__main__":
    asyncio.run(main())
