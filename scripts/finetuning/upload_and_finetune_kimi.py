#!/usr/bin/env python3
"""
–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏ –∑–∞–ø—É—Å–∫ fine-tuning –º–æ–¥–µ–ª–∏ –ù–∞—Ç–∞—à–∏ —á–µ—Ä–µ–∑ Kimi (Moonshot AI) API.

–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è: https://platform.moonshot.ai/docs/guide/migrating-from-openai-to-kimi

Kimi –∏–º–µ–µ—Ç —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å OpenAI API, –ø–æ—ç—Ç–æ–º—É –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å OpenAI SDK
—Å –∏–∑–º–µ–Ω–µ–Ω–∏–µ–º base_url –∏ API –∫–ª—é—á–∞.

–ó–∞–¥–∞—á–∏:
1. –í–∞–ª–∏–¥–∞—Ü–∏—è JSONL —Ñ–∞–π–ª–∞
2. –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ –≤ Kimi
3. –°–æ–∑–¥–∞–Ω–∏–µ fine-tuning job
4. –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
5. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ fine-tuned –º–æ–¥–µ–ª–∏
"""
import asyncio
import json
import sys
from pathlib import Path
from typing import Optional
import os

sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from openai import OpenAI
from dotenv import load_dotenv
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/finetune_kimi.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

# Kimi API endpoint
KIMI_API_BASE = "https://api.moonshot.cn/v1"


class KimiFineTuner:
    """–ö–ª–∞—Å—Å –¥–ª—è fine-tuning –º–æ–¥–µ–ª–∏ –ù–∞—Ç–∞—à–∏ –Ω–∞ Kimi."""
    
    def __init__(self):
        api_key = os.getenv('KIMI_API_KEY')
        if not api_key:
            raise ValueError("KIMI_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –≤ .env")
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º OpenAI SDK —Å Kimi endpoint
        self.client = OpenAI(
            api_key=api_key,
            base_url=KIMI_API_BASE
        )
        self.uploaded_file_id = None
        self.job_id = None
        self.model_id = None
    
    def validate_jsonl(self, file_path: str) -> bool:
        """–í–∞–ª–∏–¥–∏—Ä—É–µ—Ç JSONL —Ñ–∞–π–ª."""
        logger.info(f"Validating JSONL file: {file_path}")
        
        if not Path(file_path).exists():
            logger.error(f"File not found: {file_path}")
            return False
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                line_count = 0
                for line in f:
                    line = line.strip()
                    if not line:
                        continue
                    
                    try:
                        data = json.loads(line)
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
                        if 'messages' not in data:
                            logger.error(f"Line {line_count + 1}: Missing 'messages' field")
                            return False
                        
                        messages = data['messages']
                        if not isinstance(messages, list) or len(messages) < 2:
                            logger.error(f"Line {line_count + 1}: 'messages' must be a list with at least 2 items")
                            return False
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–æ–ª–∏
                        roles = [msg.get('role') for msg in messages]
                        if 'user' not in roles or 'assistant' not in roles:
                            logger.error(f"Line {line_count + 1}: Must have 'user' and 'assistant' roles")
                            return False
                        
                        line_count += 1
                    
                    except json.JSONDecodeError as e:
                        logger.error(f"Line {line_count + 1}: Invalid JSON - {e}")
                        return False
            
            logger.info(f"‚úÖ Validation passed: {line_count} training examples")
            return True
        
        except Exception as e:
            logger.error(f"Validation error: {e}")
            return False
    
    def upload_file(self, file_path: str) -> Optional[str]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ñ–∞–π–ª –≤ Kimi."""
        logger.info(f"Uploading file to Kimi: {file_path}")
        
        try:
            with open(file_path, 'rb') as f:
                response = self.client.files.create(
                    file=f,
                    purpose='fine-tune'
                )
            
            self.uploaded_file_id = response.id
            logger.info(f"‚úÖ File uploaded successfully to Kimi")
            logger.info(f"   File ID: {self.uploaded_file_id}")
            logger.info(f"   Size: {response.size} bytes")
            logger.info(f"   Created: {response.created_at}")
            
            return self.uploaded_file_id
        
        except Exception as e:
            logger.error(f"Upload error: {e}")
            return None
    
    def create_fine_tuning_job(
        self,
        file_id: str,
        model: str = "moonshot-v1-8k",
        n_epochs: int = 3,
        learning_rate_multiplier: float = 0.1,
        batch_size: Optional[int] = None,
        suffix: str = "natasha-v1"
    ) -> Optional[str]:
        """–°–æ–∑–¥–∞–µ—Ç fine-tuning job –≤ Kimi."""
        logger.info(f"\nCreating fine-tuning job in Kimi...")
        logger.info(f"  Model: {model}")
        logger.info(f"  Epochs: {n_epochs}")
        logger.info(f"  Learning rate multiplier: {learning_rate_multiplier}")
        logger.info(f"  Suffix: {suffix}")
        
        try:
            params = {
                'training_file': file_id,
                'model': model,
                'hyperparameters': {
                    'n_epochs': n_epochs,
                    'learning_rate_multiplier': learning_rate_multiplier
                },
                'suffix': suffix
            }
            
            if batch_size:
                params['hyperparameters']['batch_size'] = batch_size
            
            response = self.client.fine_tuning.jobs.create(**params)
            
            self.job_id = response.id
            logger.info(f"‚úÖ Fine-tuning job created successfully in Kimi")
            logger.info(f"   Job ID: {self.job_id}")
            logger.info(f"   Status: {response.status}")
            logger.info(f"   Created: {response.created_at}")
            
            return self.job_id
        
        except Exception as e:
            logger.error(f"Job creation error: {e}")
            return None
    
    def get_job_status(self, job_id: str) -> dict:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç—É—Å fine-tuning job."""
        try:
            response = self.client.fine_tuning.jobs.retrieve(job_id)
            
            status_info = {
                'id': response.id,
                'status': response.status,
                'model': response.model,
                'created_at': response.created_at,
                'updated_at': response.updated_at,
                'fine_tuned_model': response.fine_tuned_model,
                'organization_id': getattr(response, 'organization_id', None),
                'result_files': getattr(response, 'result_files', []),
                'training_file': response.training_file,
                'validation_file': getattr(response, 'validation_file', None),
                'error': getattr(response, 'error', None)
            }
            
            return status_info
        
        except Exception as e:
            logger.error(f"Error getting job status: {e}")
            return {}
    
    def monitor_job(self, job_id: str, check_interval: int = 30, max_checks: int = 1000):
        """–ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å fine-tuning job."""
        logger.info(f"\n{'='*70}")
        logger.info("MONITORING KIMI FINE-TUNING JOB")
        logger.info(f"{'='*70}")
        logger.info(f"Job ID: {job_id}")
        logger.info(f"Check interval: {check_interval} seconds")
        logger.info(f"Max checks: {max_checks}")
        logger.info(f"{'='*70}\n")
        
        check_count = 0
        
        while check_count < max_checks:
            status_info = self.get_job_status(job_id)
            
            if not status_info:
                logger.error("Failed to get job status")
                return False
            
            status = status_info.get('status')
            
            logger.info(f"[Check {check_count + 1}] Status: {status}")
            
            if status == 'succeeded':
                logger.info(f"\n‚úÖ Fine-tuning completed successfully!")
                logger.info(f"   Fine-tuned model: {status_info.get('fine_tuned_model')}")
                self.model_id = status_info.get('fine_tuned_model')
                return True
            
            elif status == 'failed':
                logger.error(f"\n‚ùå Fine-tuning failed!")
                error = status_info.get('error')
                if error:
                    logger.error(f"   Error: {error}")
                return False
            
            elif status == 'cancelled':
                logger.warning(f"\n‚ö†Ô∏è  Fine-tuning was cancelled")
                return False
            
            check_count += 1
            
            if check_count < max_checks:
                logger.info(f"   Waiting {check_interval} seconds before next check...")
                import time
                time.sleep(check_interval)
        
        logger.warning(f"\n‚ö†Ô∏è  Max checks reached. Job may still be running.")
        logger.info(f"   Check status manually with job ID: {job_id}")
        return False
    
    def test_model(self, model_id: str, test_prompts: list = None) -> dict:
        """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç fine-tuned –º–æ–¥–µ–ª—å."""
        logger.info(f"\n{'='*70}")
        logger.info("TESTING KIMI FINE-TUNED MODEL")
        logger.info(f"{'='*70}")
        logger.info(f"Model: {model_id}\n")
        
        if not test_prompts:
            test_prompts = [
                "–Ø —á—É–≤—Å—Ç–≤—É—é —Å–µ–±—è –ø–æ—Ç–µ—Ä—è–Ω–Ω—ã–º –≤ –∂–∏–∑–Ω–∏",
                "–ö–∞–∫ –Ω–∞—á–∞—Ç—å —Å–≤–æ–π –±–∏–∑–Ω–µ—Å?",
                "–Ø –≤—Å–ø–æ–º–Ω–∏–ª —Å–≤–æ—é –ø—Ä–æ—à–ª—É—é –∂–∏–∑–Ω—å",
                "–ö–∞–∫ —É–ª—É—á—à–∏—Ç—å –æ—Ç–Ω–æ—à–µ–Ω–∏—è —Å –ø–∞—Ä—Ç–Ω–µ—Ä–æ–º?",
                "–ß—Ç–æ —Ç–∞–∫–æ–µ –ø—É—Ç—å –≥–µ—Ä–æ—è?"
            ]
        
        results = []
        
        for i, prompt in enumerate(test_prompts, 1):
            logger.info(f"Test {i}: {prompt}")
            
            try:
                response = self.client.chat.completions.create(
                    model=model_id,
                    messages=[
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=500,
                    temperature=0.7
                )
                
                answer = response.choices[0].message.content
                
                logger.info(f"Response: {answer[:200]}...")
                logger.info(f"Tokens used: {response.usage.total_tokens}\n")
                
                results.append({
                    'prompt': prompt,
                    'response': answer,
                    'tokens': response.usage.total_tokens
                })
            
            except Exception as e:
                logger.error(f"Error: {e}\n")
                results.append({
                    'prompt': prompt,
                    'response': f"Error: {e}",
                    'tokens': 0
                })
        
        return results
    
    def list_jobs(self, limit: int = 10) -> list:
        """–°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö fine-tuning jobs."""
        logger.info(f"\nListing last {limit} fine-tuning jobs in Kimi...")
        
        try:
            response = self.client.fine_tuning.jobs.list(limit=limit)
            
            jobs = []
            for job in response.data:
                jobs.append({
                    'id': job.id,
                    'status': job.status,
                    'model': job.model,
                    'fine_tuned_model': job.fine_tuned_model,
                    'created_at': job.created_at,
                    'updated_at': job.updated_at
                })
            
            logger.info(f"\nFound {len(jobs)} jobs:")
            for job in jobs:
                logger.info(f"  {job['id']}: {job['status']} ({job['model']})")
                if job['fine_tuned_model']:
                    logger.info(f"    ‚Üí {job['fine_tuned_model']}")
            
            return jobs
        
        except Exception as e:
            logger.error(f"Error listing jobs: {e}")
            return []
    
    def save_config(self, output_path: str = "data/kimi_finetune_config.json"):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é fine-tuning."""
        config = {
            'provider': 'kimi',
            'api_base': KIMI_API_BASE,
            'uploaded_file_id': self.uploaded_file_id,
            'job_id': self.job_id,
            'model_id': self.model_id,
            'timestamp': str(Path(output_path).parent / 'timestamp.txt')
        }
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(config, f, ensure_ascii=False, indent=2)
        
        logger.info(f"\n‚úÖ Configuration saved to: {output_path}")
        return output_path


async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    import argparse
    
    parser = argparse.ArgumentParser(
        description="Upload dataset and run fine-tuning for Natasha model on Kimi"
    )
    parser.add_argument(
        '--file',
        type=str,
        default='data/natasha_finetuning_20251125_153356.jsonl',
        help='Path to JSONL training file'
    )
    parser.add_argument(
        '--model',
        type=str,
        default='moonshot-v1-8k',
        help='Base model for fine-tuning (default: moonshot-v1-8k)'
    )
    parser.add_argument(
        '--epochs',
        type=int,
        default=3,
        help='Number of training epochs (default: 3)'
    )
    parser.add_argument(
        '--learning-rate',
        type=float,
        default=0.1,
        help='Learning rate multiplier (default: 0.1)'
    )
    parser.add_argument(
        '--suffix',
        type=str,
        default='natasha-v1',
        help='Model suffix (default: natasha-v1)'
    )
    parser.add_argument(
        '--validate-only',
        action='store_true',
        help='Only validate the file, do not upload or train'
    )
    parser.add_argument(
        '--upload-only',
        action='store_true',
        help='Only upload the file, do not start training'
    )
    parser.add_argument(
        '--monitor',
        type=str,
        help='Monitor existing job by ID'
    )
    parser.add_argument(
        '--test',
        type=str,
        help='Test fine-tuned model by ID'
    )
    parser.add_argument(
        '--list-jobs',
        action='store_true',
        help='List all fine-tuning jobs'
    )
    
    args = parser.parse_args()
    
    print("\n" + "="*70)
    print("NATASHA FINE-TUNING UPLOADER (KIMI)")
    print("="*70 + "\n")
    
    try:
        tuner = KimiFineTuner()
    except ValueError as e:
        logger.error(f"‚ùå {e}")
        logger.error("Please set KIMI_API_KEY in .env file")
        return
    
    try:
        # –°–ø–∏—Å–æ–∫ jobs
        if args.list_jobs:
            tuner.list_jobs()
            return
        
        # –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ job
        if args.monitor:
            logger.info(f"Monitoring job: {args.monitor}")
            tuner.monitor_job(args.monitor)
            return
        
        # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
        if args.test:
            logger.info(f"Testing model: {args.test}")
            results = tuner.test_model(args.test)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            test_results_file = f"data/kimi_test_results_{args.test}.json"
            with open(test_results_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            logger.info(f"‚úÖ Test results saved to: {test_results_file}")
            return
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è —Ñ–∞–π–ª–∞
        if not tuner.validate_jsonl(args.file):
            logger.error("‚ùå Validation failed!")
            return
        
        if args.validate_only:
            logger.info("‚úÖ Validation passed. Exiting.")
            return
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞
        file_id = tuner.upload_file(args.file)
        if not file_id:
            logger.error("‚ùå Upload failed!")
            return
        
        if args.upload_only:
            logger.info(f"‚úÖ File uploaded. File ID: {file_id}")
            return
        
        # –°–æ–∑–¥–∞–Ω–∏–µ fine-tuning job
        job_id = tuner.create_fine_tuning_job(
            file_id=file_id,
            model=args.model,
            n_epochs=args.epochs,
            learning_rate_multiplier=args.learning_rate,
            suffix=args.suffix
        )
        
        if not job_id:
            logger.error("‚ùå Job creation failed!")
            return
        
        # –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ job
        logger.info("\n‚è≥ Starting to monitor fine-tuning job...")
        logger.info("   (This may take several hours)")
        
        success = tuner.monitor_job(job_id, check_interval=60)
        
        if success:
            logger.info(f"\n‚úÖ Fine-tuning completed!")
            logger.info(f"   Model ID: {tuner.model_id}")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
            tuner.save_config()
            
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å
            logger.info("\nüß™ Testing fine-tuned model...")
            results = tuner.test_model(tuner.model_id)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            test_results_file = f"data/kimi_test_results_{tuner.model_id}.json"
            with open(test_results_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            logger.info(f"‚úÖ Test results saved to: {test_results_file}")
        
        else:
            logger.warning(f"\n‚ö†Ô∏è  Fine-tuning did not complete successfully")
            logger.info(f"   Job ID: {job_id}")
            logger.info(f"   Check status manually or use --monitor flag")
    
    except Exception as e:
        logger.error(f"‚ùå Fatal error: {e}", exc_info=True)


if __name__ == "__main__":
    asyncio.run(main())
