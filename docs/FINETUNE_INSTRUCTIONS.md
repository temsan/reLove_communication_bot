# üöÄ –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ fine-tuning –º–æ–¥–µ–ª–∏ –ù–∞—Ç–∞—à–∏

**–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è OpenAI**: https://platform.openai.com/docs/guides/supervised-fine-tuning

---

## üìã –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è

1. **OpenAI API –∫–ª—é—á** —Å –¥–æ—Å—Ç—É–ø–æ–º –∫ fine-tuning
   - –ü–æ–ª—É—á–∏—Ç—å –Ω–∞ https://platform.openai.com/api-keys
   - –î–æ–±–∞–≤–∏—Ç—å –≤ `.env` —Ñ–∞–π–ª: `OPENAI_API_KEY=sk-...`

2. **Python 3.8+** —Å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–º–∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—è–º–∏
   ```bash
   pip install openai python-dotenv
   ```

3. **–î–∞—Ç–∞—Å–µ—Ç** –≥–æ—Ç–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSONL
   - –§–∞–π–ª: `data/natasha_finetuning_20251125_153356.jsonl`
   - 321 QA –ø–∞—Ä–∞
   - –ü—Ä–æ–≤–µ—Ä–µ–Ω–æ –∏ –≥–æ—Ç–æ–≤–æ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é

---

## üéØ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç (3 —à–∞–≥–∞)

### –®–∞–≥ 1: –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞

```bash
python scripts/analysis/upload_and_finetune_natasha.py --validate-only
```

**–û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç**:
```
‚úÖ Validation passed: 321 training examples
```

### –®–∞–≥ 2: –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –∑–∞–ø—É—Å–∫ fine-tuning

```bash
python scripts/analysis/upload_and_finetune_natasha.py
```

**–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é**:
- Model: `gpt-4-turbo`
- Epochs: `3`
- Learning rate: `0.1`
- Suffix: `natasha-v1`

**–û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç**:
```
‚úÖ File uploaded successfully
   File ID: file-xxx

‚úÖ Fine-tuning job created successfully
   Job ID: ftjob-xxx
   Status: queued

‚è≥ Starting to monitor fine-tuning job...
   (This may take several hours)
```

### –®–∞–≥ 3: –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞

–°–∫—Ä–∏–ø—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –º–æ–Ω–∏—Ç–æ—Ä–∏—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 60 —Å–µ–∫—É–Ω–¥.

**–°—Ç–∞—Ç—É—Å—ã**:
- `queued` ‚Äî –æ–∂–∏–¥–∞–Ω–∏–µ –Ω–∞—á–∞–ª–∞
- `running` ‚Äî –∏–¥–µ—Ç –æ–±—É—á–µ–Ω–∏–µ
- `succeeded` ‚Äî —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–æ ‚úÖ
- `failed` ‚Äî –æ—à–∏–±–∫–∞ ‚ùå
- `cancelled` ‚Äî –æ—Ç–º–µ–Ω–µ–Ω–æ ‚ö†Ô∏è

---

## üîß –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã

### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –¥—Ä—É–≥–æ–π –º–æ–¥–µ–ª–∏

```bash
python scripts/analysis/upload_and_finetune_natasha.py \
  --model gpt-4-turbo \
  --epochs 5 \
  --learning-rate 0.05 \
  --suffix natasha-gpt4-v1
```

### –ü–∞—Ä–∞–º–µ—Ç—Ä—ã

| –ü–∞—Ä–∞–º–µ—Ç—Ä | –ó–Ω–∞—á–µ–Ω–∏–µ | –û–ø–∏—Å–∞–Ω–∏–µ |
|----------|----------|---------|
| `--file` | path | –ü—É—Ç—å –∫ JSONL —Ñ–∞–π–ª—É |
| `--model` | gpt-3.5-turbo | –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å |
| `--epochs` | 3 | –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö –æ–±—É—á–µ–Ω–∏—è |
| `--learning-rate` | 0.1 | –ú–Ω–æ–∂–∏—Ç–µ–ª—å learning rate |
| `--suffix` | natasha-v1 | –°—É—Ñ—Ñ–∏–∫—Å –¥–ª—è –∏–º–µ–Ω–∏ –º–æ–¥–µ–ª–∏ |

### –†–µ–∂–∏–º—ã —Ä–∞–±–æ—Ç—ã

```bash
# –¢–æ–ª—å–∫–æ –≤–∞–ª–∏–¥–∞—Ü–∏—è
python scripts/analysis/upload_and_finetune_natasha.py --validate-only

# –¢–æ–ª—å–∫–æ –∑–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞
python scripts/analysis/upload_and_finetune_natasha.py --upload-only

# –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ job
python scripts/analysis/upload_and_finetune_natasha.py --monitor ftjob-xxx

# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ fine-tuned –º–æ–¥–µ–ª–∏
python scripts/analysis/upload_and_finetune_natasha.py --test ft:gpt-3.5-turbo:org-xxx::yyy

# –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö jobs
python scripts/analysis/upload_and_finetune_natasha.py --list-jobs
```

---

## üìä –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã

### –î–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è

```bash
python scripts/analysis/upload_and_finetune_natasha.py \
  --epochs 1 \
  --learning-rate 0.2 \
  --suffix natasha-test
```

**–í—Ä–µ–º—è**: ~30 –º–∏–Ω—É—Ç  
**–°—Ç–æ–∏–º–æ—Å—Ç—å**: ~$5-10

### –î–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞

```bash
python scripts/analysis/upload_and_finetune_natasha.py \
  --epochs 3 \
  --learning-rate 0.1 \
  --suffix natasha-prod-v1
```

**–í—Ä–µ–º—è**: ~2-3 —á–∞—Å–∞  
**–°—Ç–æ–∏–º–æ—Å—Ç—å**: ~$15-25

### –î–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞

```bash
python scripts/analysis/upload_and_finetune_natasha.py \
  --model gpt-4-turbo \
  --epochs 5 \
  --learning-rate 0.05 \
  --suffix natasha-premium-v1
```

**–í—Ä–µ–º—è**: ~4-5 —á–∞—Å–æ–≤  
**–°—Ç–æ–∏–º–æ—Å—Ç—å**: ~$50-100

---

## üí∞ –°—Ç–æ–∏–º–æ—Å—Ç—å

**–¶–µ–Ω—ã –Ω–∞ fine-tuning** (–∑–∞ 1K —Ç–æ–∫–µ–Ω–æ–≤):

| –ú–æ–¥–µ–ª—å | Training | Input | Output |
|--------|----------|-------|--------|
| gpt-3.5-turbo | $0.03 | $0.0005 | $0.0015 |
| gpt-4-turbo | $0.06 | $0.01 | $0.03 |

**–ü—Ä–∏–º–µ—Ä–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å –¥–ª—è –Ω–∞—à–µ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞**:
- gpt-3.5-turbo, 3 —ç–ø–æ—Ö–∏: ~$15-20
- gpt-4-turbo, 3 —ç–ø–æ—Ö–∏: ~$40-50

---

## üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏

### –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

–ü–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ fine-tuning —Å–∫—Ä–∏–ø—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä—É–µ—Ç –º–æ–¥–µ–ª—å –Ω–∞ 5 –ø—Ä–∏–º–µ—Ä–∞—Ö:

```
Test 1: –Ø —á—É–≤—Å—Ç–≤—É—é —Å–µ–±—è –ø–æ—Ç–µ—Ä—è–Ω–Ω—ã–º –≤ –∂–∏–∑–Ω–∏
Response: [–æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏]

Test 2: –ö–∞–∫ –Ω–∞—á–∞—Ç—å —Å–≤–æ–π –±–∏–∑–Ω–µ—Å?
Response: [–æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏]

...
```

### –†—É—á–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

```bash
# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏
python scripts/analysis/upload_and_finetune_natasha.py \
  --test ft:gpt-3.5-turbo:org-xxx::yyy
```

### –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ Python

```python
from openai import OpenAI

client = OpenAI()

response = client.chat.completions.create(
    model="ft:gpt-3.5-turbo:org-xxx::yyy",  # –í–∞—à–∞ fine-tuned –º–æ–¥–µ–ª—å
    messages=[
        {"role": "user", "content": "–Ø —á—É–≤—Å—Ç–≤—É—é —Å–µ–±—è –ø–æ—Ç–µ—Ä—è–Ω–Ω—ã–º"}
    ],
    max_tokens=500,
    temperature=0.7
)

print(response.choices[0].message.content)
```

---

## üìà –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –≤ OpenAI Dashboard

1. –ü–µ—Ä–µ–π—Ç–∏ –Ω–∞ https://platform.openai.com/fine-tuning/jobs
2. –ù–∞–π—Ç–∏ –≤–∞—à job –ø–æ ID
3. –°–º–æ—Ç—Ä–µ—Ç—å —Å—Ç–∞—Ç—É—Å –∏ –º–µ—Ç—Ä–∏–∫–∏ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏

**–î–æ—Å—Ç—É–ø–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏**:
- Training loss
- Validation loss
- Tokens processed
- Estimated time remaining

---

## ‚ö†Ô∏è –†–µ—à–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º

### –û—à–∏–±–∫–∞: "Invalid API key"

```bash
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, —á—Ç–æ OPENAI_API_KEY —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω
echo $OPENAI_API_KEY

# –î–æ–±–∞–≤–∏—Ç—å –≤ .env
OPENAI_API_KEY=sk-...
```

### –û—à–∏–±–∫–∞: "File validation failed"

```bash
# –ü–µ—Ä–µvalid–∏—Ä–æ–≤–∞—Ç—å —Ñ–∞–π–ª
python scripts/analysis/upload_and_finetune_natasha.py --validate-only

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ñ–æ—Ä–º–∞—Ç JSONL
head -1 data/natasha_finetuning_20251125_153356.jsonl | python -m json.tool
```

### Job –∑–∞–≤–∏—Å–∞–µ—Ç –Ω–∞ "queued"

- –≠—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ, –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç
- –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ç–∞—Ç—É—Å –≤ OpenAI Dashboard
- –ï—Å–ª–∏ –∑–∞–≤–∏—Å–∞–µ—Ç > 1 —á–∞—Å–∞, –æ—Ç–º–µ–Ω–∏—Ç—å –∏ –ø–µ—Ä–µ—Å–æ–∑–¥–∞—Ç—å

### –ù–∏–∑–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –æ—Ç–≤–µ—Ç–æ–≤

- –£–≤–µ–ª–∏—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö (epochs)
- –£–º–µ–Ω—å—à–∏—Ç—å learning rate
- –î–æ–±–∞–≤–∏—Ç—å –±–æ–ª—å—à–µ –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ –¥–∞—Ç–∞—Å–µ—Ç
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–æ–ª–µ–µ –º–æ—â–Ω—É—é –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å (gpt-4)

---

## üìù –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

### –ü—Ä–∏–º–µ—Ä 1: –ë—ã—Å—Ç—Ä–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

```bash
# –í–∞–ª–∏–¥–∞—Ü–∏—è
python scripts/analysis/upload_and_finetune_natasha.py --validate-only

# –ó–∞–≥—Ä—É–∑–∫–∞
python scripts/analysis/upload_and_finetune_natasha.py --upload-only

# –ó–∞–ø—É—Å–∫ —Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
python scripts/analysis/upload_and_finetune_natasha.py \
  --epochs 1 \
  --suffix natasha-test
```

### –ü—Ä–∏–º–µ—Ä 2: –ü—Ä–æ–¥–∞–∫—à–Ω fine-tuning

```bash
python scripts/analysis/upload_and_finetune_natasha.py \
  --model gpt-3.5-turbo \
  --epochs 3 \
  --learning-rate 0.1 \
  --suffix natasha-prod-v1
```

### –ü—Ä–∏–º–µ—Ä 3: –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ job

```bash
# –ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö jobs
python scripts/analysis/upload_and_finetune_natasha.py --list-jobs

# –ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π job
python scripts/analysis/upload_and_finetune_natasha.py --monitor ftjob-xxx
```

### –ü—Ä–∏–º–µ—Ä 4: –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏

```bash
python scripts/analysis/upload_and_finetune_natasha.py \
  --test ft:gpt-3.5-turbo:org-xxx::yyy
```

---

## üîÑ Workflow

```
1. –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞
   ‚Üì
2. –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ –≤ OpenAI
   ‚Üì
3. –°–æ–∑–¥–∞–Ω–∏–µ fine-tuning job
   ‚Üì
4. –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ (–º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å —á–∞—Å—ã)
   ‚Üì
5. –ü–æ–ª—É—á–µ–Ω–∏–µ fine-tuned –º–æ–¥–µ–ª–∏
   ‚Üì
6. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
   ‚Üì
7. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤ production
```

---

## üìä –û–∂–∏–¥–∞–µ–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

–ü–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ fine-tuning –º–æ–¥–µ–ª—å –¥–æ–ª–∂–Ω–∞:

‚úÖ **–û—Ç–≤–µ—á–∞—Ç—å –≤ —Å—Ç–∏–ª–µ –ù–∞—Ç–∞—à–∏**
- –ü—Ä–æ–≤–æ–∫–∞—Ç–∏–≤–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã
- –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∏–π —Ç–æ–Ω
- –ú–µ—Ç–∞—Ñ–æ—Ä—ã –∏ –æ–±—Ä–∞–∑—ã

‚úÖ **–†–∞–±–æ—Ç–∞—Ç—å —Å –æ—Å–Ω–æ–≤–Ω—ã–º–∏ —Ç–µ–º–∞–º–∏**
- –î—É—Ö–æ–≤–Ω–æ–µ —Ä–∞–∑–≤–∏—Ç–∏–µ
- –û—Ç–Ω–æ—à–µ–Ω–∏—è
- –ë–∏–∑–Ω–µ—Å
- –ü—Ä–æ—à–ª—ã–µ –∂–∏–∑–Ω–∏

‚úÖ **–°–æ—Ö—Ä–∞–Ω—è—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç**
- –ü–æ–º–Ω–∏—Ç—å –ø—Ä–µ–¥—ã–¥—É—â–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è
- –î–∞–≤–∞—Ç—å —Å–≤—è–∑–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã
- –†–∞–∑–≤–∏–≤–∞—Ç—å –∏–¥–µ–∏

---

## üìö –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã

- [OpenAI Fine-tuning Guide](https://platform.openai.com/docs/guides/supervised-fine-tuning)
- [OpenAI API Reference](https://platform.openai.com/docs/api-reference)
- [Fine-tuning Best Practices](https://platform.openai.com/docs/guides/fine-tuning/best-practices)
- [Pricing](https://openai.com/pricing)

---

## üéØ –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏

1. ‚úÖ –î–∞—Ç–∞—Å–µ—Ç –≥–æ—Ç–æ–≤
2. ‚è≠Ô∏è –ó–∞–ø—É—Å—Ç–∏—Ç—å fine-tuning
3. ‚è≠Ô∏è –î–æ–∂–¥–∞—Ç—å—Å—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
4. ‚è≠Ô∏è –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å
5. ‚è≠Ô∏è –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å –≤ production
6. ‚è≠Ô∏è –ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ

---

**–ì–æ—Ç–æ–≤–æ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!** üöÄ

–í–æ–ø—Ä–æ—Å—ã? –°–º–æ—Ç—Ä–∏—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é OpenAI –∏–ª–∏ –ª–æ–≥–∏ –≤ `logs/finetune_natasha.log`
